import joblib
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
# joblib: Ù„Ø­ÙØ¸ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ù…Ø«Ù„ StandardScaler.
# torch.*: Ù„Ø¨Ù†Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©.
# pandas, numpy: Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
# matplotlib: Ù„Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©.
# os: Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª.
# Ù…Ù† sklearn.metrics: Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.
# Ù…Ù† sklearn.preprocessing: Ù„ØªØ­Ø¬ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
import geopandas as gpd
import matplotlib.pyplot as plt


from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix, mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
# Ø£Ø¯ÙˆØ§Øª ØªÙ‚ÙŠÙŠÙ… Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙÙŠØ© ÙˆØ§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±ÙŠØ©.
# XGBRegressor: Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø­Ø¯Ø§Ø± Ù…Ù† Ù…ÙƒØªØ¨Ø© XGBoost.


from earthquake_risk_predictor.src.PyTorch_predictor.model import EarthquakeModel
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ.


# Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ§Ù„Ø± ÙŠØ³ØªØ®Ø¯Ù… Ù„Ø§Ø­Ù‚Ù‹Ø§ Ù„ØªÙˆØ­ÙŠØ¯ y_train_reg Ø«Ù… ÙŠÙØ­ÙØ¸.
reg_scaler = StandardScaler()



#  Ø¯Ø§Ù„Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
def train_model(model, X_train, X_test, y_train_class, y_test_class, y_train_reg, y_test_reg, save_path='model.pt'):

# ØªÙˆØ­ÙŠØ¯ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±
# ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ y_train_reg (magnitude Ùˆ depth).
#     ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ§Ù„Ø± Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§ ÙÙŠ inference.
#     1. ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… StandardScaler.
#     2. Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ§Ù„Ø± ÙÙŠ Ù…Ù„Ù pickle Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§.
    global reg_scaler
    reg_scaler = StandardScaler()
    y_train_reg_scaled = reg_scaler.fit_transform(y_train_reg)
    y_test_reg_scaled = reg_scaler.transform(y_test_reg)
    joblib.dump(reg_scaler, "earthquake_risk_predictor/data/reg_scaler.pkl")

# Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ (CPU Ø£Ùˆ GPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

# Ø­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Tensor
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)
    y_train_class_tensor = torch.tensor(y_train_class.values, dtype=torch.long).to(device)
    y_train_reg_tensor = torch.tensor(y_train_reg_scaled, dtype=torch.float32).to(device)
    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ØªØ¯Ø±ÙŠØ¨: Adam
    # Ø¯ÙˆØ§Ù„ Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ØªØµÙ†ÙŠÙ ÙˆØ§Ù†Ø­Ø¯Ø§Ø±.
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion_class = nn.CrossEntropyLoss()
    criterion_reg = nn.MSELoss()
    
    
#  ØªØ¯Ø±ÙŠØ¨ 100 Ø­Ù‚Ø¨Ø© (epoch)
    model.train()
    for epoch in range(250):
        
        # Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
        # ØªØµÙÙŠØ± Ø§Ù„ØªØ¯Ø±Ø¬.
        # ØªÙ†ÙÙŠØ° forward pass.
        optimizer.zero_grad()
        out_class, out_reg = model(X_train_tensor)

        loss_class = criterion_class(out_class, y_train_class_tensor)

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        try:
            loss_reg = criterion_reg(out_reg, y_train_reg_tensor)
            if torch.isnan(loss_reg) or torch.isinf(loss_reg):
                print(f"âš ï¸ Epoch {epoch+1}: Regression loss is unstable. Skipping regression.")
                loss = loss_class
            else:
                # Ù†Ø¯Ù…Ø¬ Ø§Ù„Ø®Ø³Ø§Ø±ØªÙŠÙ†ØŒ Ù…Ø¹ ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø¨Ù…Ø¹Ø§Ù…Ù„ 2.0.
                loss = loss_class + 0.2 * loss_reg
        except Exception as e:
            print(f"âš ï¸ Regression loss error: {e}")
            loss = loss_class
            
# Ø§Ù„ØªØ¯Ø±Ø¬ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«
        loss.backward()
        optimizer.step()
        print(f"Epoch {epoch+1}/250 - Loss: {loss.item():.4f}")

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    torch.save(model.state_dict(), save_path)
    print(f"\nâœ… Model saved to '{save_path}'")
    
#  Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    
    # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
    model.eval()
    with torch.no_grad():
        # ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ù„Ù‰ Tensor.
        # ØªÙ†ÙÙŠØ° forward pass.
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª.Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ¦Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ.
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¥Ù„Ù‰ numpy.
        # Ø­Ø³Ø§Ø¨ Ø¯Ù‚Ø© Ø§Ù„ØªØµÙ†ÙŠÙ.
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ¦Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ.
        preds_class, preds_reg = model(X_test_tensor)
        # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„Ø§Ù†Ø­Ø¯Ø§Ø±
        # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ magnitude, depth Ø¨Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£ØµÙ„ÙŠØ©.
        preds_class_labels = torch.argmax(preds_class, axis=1).cpu().numpy()

        try:
            preds_reg_np = preds_reg.cpu().numpy()
            preds_reg_inv = reg_scaler.inverse_transform(preds_reg_np)
        except Exception as e:
            print(f"âš ï¸ Regression prediction scaling failed: {e}")
            preds_reg_inv = np.zeros_like(y_test_reg)

        print("\nğŸ“Š Classification Report:")
        print(classification_report(
            y_test_class,
            preds_class_labels,
            target_names=['Hafif', 'Orta', 'GÃ¼Ã§lÃ¼', 'Åiddetli', 'Felaket']
        ))

        try:
 
            # Ø­Ø³Ø§Ø¨ MSE Ù„Ù„Ø§Ù†Ø­Ø¯Ø§Ø±.
            # Ø­Ø³Ø§Ø¨ MSE Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… sklearn.metrics.
            mse = mean_squared_error(y_test_reg, preds_reg_inv)
            print("\nğŸ“‰ Regression MSE:")
            print(mse)
            
            # ğŸ“Š Confusion Matrix
            #  Ø­ÙØ¸ Ø§Ù„Ù…ØµÙÙˆÙØ© ÙˆØ§Ù„ØªÙˆØ²ÙŠØ¹
            cm = confusion_matrix(y_test_class, preds_class_labels)
            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Hafif', 'Orta', 'GÃ¼Ã§lÃ¼', 'Åiddetli', 'Felaket'])
            disp.plot(cmap='Blues', xticks_rotation=45)
            plt.title("Confusion Matrix")
            plt.tight_layout()
            os.makedirs("data", exist_ok=True)
            plt.savefig("earthquake_risk_predictor/data/confusion_matrix.png")
            print("ğŸ“Š Saved confusion matrix to 'earthquake_risk_predictor/data/confusion_matrix.png'")
            
            # Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø®Ø·Ø£.
            errors = np.abs(y_test_reg.values - preds_reg_inv)
            plt.figure(figsize=(10, 4))
            plt.hist(errors[:, 0], bins=30, alpha=0.6, label='Magnitude Error')
            plt.hist(errors[:, 1], bins=30, alpha=0.6, label='Depth Error')
            plt.title("Regression Error Distribution")
            plt.legend()
            plt.tight_layout()
            os.makedirs("data", exist_ok=True)
            plt.savefig("earthquake_risk_predictor/data/regression_errors.png")
            print("ğŸ“‰ Saved regression error distribution to 'earthquake_risk_predictor/data/regression_errors.png'")
        except Exception as e:
            print(f"âš ï¸ Error calculating regression metrics: {e}")



# Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
# Ù†ÙØ³ ÙÙƒØ±Ø© predict Ù„ÙƒÙ† ØªØ­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ CSV.
def predict_and_save_outputs(model, X_test, y_test_class, y_test_reg, output_path="earthquake_risk_predictor/data/predictions.csv"):
    global reg_scaler
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

# Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤:
    with torch.no_grad():
        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)
        preds_class, preds_reg = model(X_test_tensor)
        class_labels = torch.argmax(preds_class, axis=1).cpu().numpy()
        preds_reg = reg_scaler.inverse_transform(preds_reg.cpu().numpy())


# Ø­ÙØ¸ CSV:
    df_out = pd.DataFrame(X_test, columns=[f"feat_{i}" for i in range(X_test.shape[1])])
    df_out["true_class"] = y_test_class.values
    df_out["pred_class"] = class_labels
    df_out["true_magnitude"] = y_test_reg.iloc[:, 0].values
    df_out["pred_magnitude"] = preds_reg[:, 0]
    df_out["true_depth_km"] = y_test_reg.iloc[:, 1].values
    df_out["pred_depth_km"] = preds_reg[:, 1]

    df_out.to_csv(output_path, index=False)
    print(f"ğŸ“„ Predictions saved to {output_path}")



# Ø§Ù†Ø­Ø¯Ø§Ø± XGBoost
def run_xgboost_regressor(X_train, X_test, y_train_reg, y_test_reg):
    os.makedirs("data", exist_ok=True)
    results = {}

# ÙŠØ¯Ø±Ø¨ Ù†Ù…ÙˆØ°Ø¬ XGBRegressor Ù„ÙƒÙ„ Ù…Ù† magnitude, depth_km.
    for i, label in enumerate(["magnitude", "depth_km"]):
        model = XGBRegressor(n_estimators=100, max_depth=4, random_state=42)
        model.fit(X_train, y_train_reg.iloc[:, i])
        preds = model.predict(X_test)

        mse = mean_squared_error(y_test_reg.iloc[:, i], preds)
        r2 = r2_score(y_test_reg.iloc[:, i], preds)
        mae = mean_absolute_error(y_test_reg.iloc[:, i], preds)

        results[label] = {"MSE": mse, "MAE": mae, "R2": r2}
        plt.figure()
        #  Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.
        # Ø±Ø³Ù… Ø§Ù„ØªÙˆÙ‚Ø¹ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ.
        plt.scatter(y_test_reg.iloc[:, i], preds, alpha=0.5)
        plt.xlabel(f"True {label}")
        plt.ylabel(f"Predicted {label}")
        plt.title(f"XGBoost Prediction: {label}")
        plt.grid(True)
        plt.tight_layout()
        plt.savefig(f"earthquake_risk_predictor/data/xgboost_results_{label}.png")

# Ø­ÙØ¸ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ CSV.
    pd.DataFrame(results).T.to_csv("earthquake_risk_predictor/data/xgboost_metrics.csv")
    print("ğŸ“Š XGBoost metrics saved to 'earthquake_risk_predictor/data/xgboost_metrics.csv'")


#  Ø®Ø±ÙŠØ·Ø© ØªØ±ÙƒÙŠØ§
def plot_geographic_distribution(df, lat_col="latitude", lon_col="longitude", border_file="tr.json"):
    """
    Plots earthquakes on a Turkey map using GeoJSON borders.
    """
    # ØªØ­ÙˆÙŠÙ„ DataFrame Ø¥Ù„Ù‰ GeoDataFrame
    # ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù„Ø§Ø²Ù„ Ø¥Ù„Ù‰ Ø®Ø±ÙŠØ·Ø©.
    gdf = gpd.GeoDataFrame(
        df,
        geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),
        crs="EPSG:4326"
    )

    # ØªØ­Ù…ÙŠÙ„ Ø­Ø¯ÙˆØ¯ ØªØ±ÙƒÙŠØ§
    if os.path.exists(border_file):
        turkey = gpd.read_file(border_file)
    else:
        print("âš ï¸ GeoJSON sÄ±nÄ±r dosyasÄ± bulunamadÄ±.")
        turkey = gpd.GeoDataFrame()

    # Ø±Ø³Ù… Ø§Ù„Ø®Ø±ÙŠØ·Ø©
    fig, ax = plt.subplots(figsize=(10, 8))
    if not turkey.empty:
        turkey.boundary.plot(ax=ax, color="black", linewidth=0.8)



    # Ø±Ø³Ù… Ø§Ù„Ø²Ù„Ø§Ø²Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø±ÙŠØ·Ø©.
    # ØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø²Ù„Ø§Ø²Ù„ Ø­Ø³Ø¨ magnitude.
    gdf.plot(
        ax=ax,
        column='magnitude',
        cmap='Reds',
        markersize=30,
        legend=True,
        alpha=0.6
    )

    plt.title("Earthquake Geographic Distribution (Turkey)")
    plt.xlabel("Longitude")
    plt.ylabel("Latitude")
    plt.grid(True)
    plt.tight_layout()
    os.makedirs("data", exist_ok=True)
    plt.savefig("earthquake_risk_predictor/data/geographic_distribution.png")
    print("ğŸ—ºï¸ Saved geographic map with borders to 'data/geographic_distribution.png'")